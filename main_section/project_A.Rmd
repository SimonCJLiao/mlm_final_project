---
title: "Project A1+A2 - Model Selection and Notation"
author: "Chongjun Liao, Jeremy Lu"
date: "5/7/2022"
output: pdf_document
---
  
  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lme4)
library(lmerTest)
library(dplyr)
library(aod)
```

0. We will use the classroom.csv data for this project. 
a. math1st will be the outcome of interest for this first part  
i. Recall that `math1st = mathkind + mathgain` 
b. Read in the data (R: store as `dat`) 
c. Fit all models using REML 
d. It’s best if you use `lmerTest::lmer` rather than `lme4::lmer` to call the MLM function. The former provides p-values for fixed effects in the summary. 
e. There are 2 common error messages one can get from lmer calls: failed to converge (problem with hessian: negative eigenvalue; max|grad| = ...); and singularity. They may both be problematic in a real problem, but the latter suggests that a variance component is on the boundary of the parameter space.  
1. In your discussion/writeup, consider the latter to be a “convergence problem” and ignore the former. 
```{r}
dat <- read.csv("~/Documents/GitHub/mlm_final_project/data/classroom.csv")
dat <- dat %>% 
  mutate(math1st = mathkind + mathgain)
```
1. Estimate an Unconditional Means Model (UMM) with random intercepts for both schools and classrooms (nested in schools).  

```{r q1}
fit1 <- lmer( math1st ~ (1 | schoolid/classid), dat)
summary(fit1)
```

a. Report the ICC for schools and the ICC for classrooms 
**Answer:** The ICC for schools is `r as.data.frame(VarCorr(fit1))$vcov[2]/as.data.frame(VarCorr(fit1))$vcov[3]` and the ICC for classrooms is `r as.data.frame(VarCorr(fit1))$vcov[1]/as.data.frame(VarCorr(fit1))$vcov[3]`.  
b. **WRITE OUT THIS MODEL** using your preferred notation, but use the same choice of notation for the remainder of your project 
i. Be mindful and explicit about any assumptions made. 
$MATH1ST_{ijk} = {b_0} + \zeta _{0k} + \eta _{0jk}+ {\varepsilon _{ijk}}$, with
${\zeta_{0k}}\sim N(0,\sigma_{\zeta_0}^2)$,
$\eta _{0jk} \sim N(0,\sigma_{\eta_0}^2)$ and 
${\varepsilon_{ijk}}\sim N(0,\sigma_\varepsilon^2)$, 
independently of one another, *j*
  represents classrooms and *k*
  represents *schools*.
2. ADD ALL School level predictors 
```{r q2}
fit1 <- lmer( math1st ~ (1 | schoolid/classid), dat)
fit2 <- lmer( math1st ~ housepov + (1 | schoolid/classid), dat)
summary(fit2)
anova(fit1,fit2)
```
a. Report if adding the predictors as a block is justified 
There is only one school-level predictor which is `housepov`, its p-value is `r summary(fit2)$coef["housepov",'Pr(>|t|)']` < 0.05, and I do a LRT on model with and without the school-level predictor, the p-value is `r anova(fit1,fit2)[,'Pr(>Chisq)'][2]` < 0.05. So it is reasonable to add school-level predictor.
b. Report change in $\sigma_\zeta^2$. 
The change in $\sigma_\zeta^2$ is `r as.data.frame(VarCorr(fit1))$vcov[2]`-`r as.data.frame(VarCorr(fit2))$vcov[2]` = `r as.data.frame(VarCorr(fit1))$vcov[2] - as.data.frame(VarCorr(fit2))$vcov[2]`.
3. ADD ALL Classroom level predictors 
```{r q3}
save.options = options()
options(na.action = "na.pass")
mm <- model.matrix(~math1st + ses + mathknow, data = dat)
in_sample <- apply(is.na(mm), 1, sum) == 0 # these rows aren't missing anything 
options(save.options)
# remove those na 
fit3 <- lmer( math1st ~ yearstea + mathknow + mathprep + housepov + (1 | schoolid/classid), 
              dat, subset = in_sample)
summary(fit3)
wald.test(b = fixef(fit3), Sigma = summary(fit3)$vcov, Terms = 2:4)
```

a. Report if adding the predictors as a block is justified [must use WALD test, not LRT] 
**Answer:** The Wald test generates a p-value = 0.22, which shows that we have no reason to add classroom-level predictors as a block. But it might be reasonable to include `mathknow` since it is significant according to the t-test.
b. Report change in $\sigma^2_\eta$ and change in $\sigma^2_\epsilon$. 
The change in $\sigma_\eta^2$ is `r as.data.frame(VarCorr(fit3))$vcov[1]`-`r as.data.frame(VarCorr(fit1))$vcov[1]` = `r as.data.frame(VarCorr(fit3))$vcov[1] - as.data.frame(VarCorr(fit1))$vcov[1]` and change in $\sigma^2_\epsilon$ is `r as.data.frame(VarCorr(fit3))$vcov[3]`-`r as.data.frame(VarCorr(fit1))$vcov[3]` = `r as.data.frame(VarCorr(fit3))$vcov[3] - as.data.frame(VarCorr(fit1))$vcov[3]`.
c. Give a potential reason as to why $\sigma^2_\epsilon$ is reduced, but not $\sigma^2_\eta$? 
  4. ADD (nearly) ALL student level predictors (but not `mathgain` or `mathkind`, as these are outcomes in this context). 
```{r}
fit4 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                housepov + (1 | schoolid/classid), dat, subset = in_sample)
summary(fit4)
wald.test(b = fixef(fit4), Sigma = summary(fit4)$vcov, Terms = 2:4)
```

a. Report if justified statistically as a block of predictors [must use WALD test, not LRT] 
The wald test gives a p-value less than 0.05, which justifies the significance of adding a block of individual predictors.
b. Report change in variance components for all levels 
The change in $\sigma_\eta^2$ is `r as.data.frame(VarCorr(fit4))$vcov[1]`-`r as.data.frame(VarCorr(fit1))$vcov[1]` = `r as.data.frame(VarCorr(fit4))$vcov[1] - as.data.frame(VarCorr(fit1))$vcov[1]`, the change in $\sigma_\zeta^2$ is `r as.data.frame(VarCorr(fit4))$vcov[2]`-`r as.data.frame(VarCorr(fit1))$vcov[2]` = `r as.data.frame(VarCorr(fit4))$vcov[2] - as.data.frame(VarCorr(fit1))$vcov[2]` and change in $\sigma^2_\epsilon$ is `r as.data.frame(VarCorr(fit4))$vcov[3]`-`r as.data.frame(VarCorr(fit1))$vcov[3]` = `r as.data.frame(VarCorr(fit4))$vcov[3] - as.data.frame(VarCorr(fit1))$vcov[3]`.
c. Give a potential reason as to why the school level variance component drops from prior model 
Individual predictors are correlated with school-level effect.
d. WRITE OUT THIS MODEL using your chosen notation (include assumptions).  
$MATH1ST_{ijk} = {b_0} + b_1SES_{ijk} + b_2MINORITY_{ijk} + b_3SEX_{ijk} + b_4YEARSTEA_{jk} + b_5MATHKNOW_{jk} + b_6MATHPREP_{jk}+ b_7HOUSEPOV_{k} + \zeta _{0k} + \eta _{0jk}+ {\varepsilon _{ijk}}$, with
${\zeta_{0k}}\sim N(0,\sigma_{\zeta_0}^2)$,
$\eta _{0jk} \sim N(0,\sigma_{\eta_0}^2)$ and 
${\varepsilon_{ijk}}\sim N(0,\sigma_\varepsilon^2)$, 
independently of one another, *j*
  represents classrooms and *k*
  represents *schools*.
5.a. Try to add a random slope for each teacher level predictor (varying at the school level; one by one separately- not all together) 
b. Report the model fit or lack of fit 
```{r}
fit5.1 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                  housepov + (1 | schoolid/classid) + (0 + yearstea || schoolid), 
                dat, subset = in_sample)
summary(fit5.1)
```
```{r}
fit5.2 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                  housepov + (1 | schoolid/classid) + (0 + yearstea + mathknow || schoolid),
                dat, subset = in_sample)
summary(fit5.2)
```
```{r}
fit5.3 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                  housepov + (1 | schoolid/classid) + (0 + yearstea + mathknow + mathprep || schoolid), 
                dat, subset = in_sample)
summary(fit5.3)
```
c. Retry the above, allowing the slopes to be correlated with the random intercepts (still one by one) 
```{r}
fit5.c.1 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                    housepov + (1 | schoolid/classid) + (yearstea || schoolid), 
                  dat, subset = in_sample)
fit5.c.2 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                    housepov + (1 | schoolid/classid) + (yearstea + mathknow|| schoolid), 
                  dat, subset = in_sample)
fit5.c.3 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                    housepov + (1 | schoolid/classid) + (yearstea + mathknow + mathprep || schoolid), 
                  dat, subset = in_sample)
```

d. Report anything unusual about the variance components (changes that are in a direction you didn’t expect) and any potential explanation for why those changes occurred (hint: what did you add to the model?).  

6. Question: 
  a. Why is it a bad idea to include a classroom-level variable with random slopes at the classroom level?
  
7. Question:
  a. For UMM, write down: V_S, V_C, V_E for the three variance components (simply the estimates)
 **Answer:**  We have that V_S = 280.68, V_C = 85.46, and V_E = 1146.8
  b. For the most complicated (all fixed effects) random INTERCEPTS ONLY model, what are: V_C, V_S, V_E?
  **Answer:** We have in this model that V_S = 169.45, V_C = 93.89, V_E = 1064.96
  c. By what fraction did these each decrease with the new predictors in the model?
  **Answer:** The fraction decrease for V_S, and V_E are `round((280.68-169.45)/280.68, 2)`, and `round((1146.8-1064.96)/1146.8, 2)`, respectively. But for V_C it actually increased `round((93.89-85.46)/85.46, 2)` fraction-wise.
  
8. a. 
```{r}
fit8.a.1 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                housepov + (1 | schoolid/classid) + (0 + ses || schoolid), dat, subset = in_sample)
summary(fit8.a.1)
```

```{r}
fit8.a.2 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                housepov + (1 | schoolid/classid) + (0 + sex || schoolid), dat, subset = in_sample)
summary(fit8.a.2)
```

```{r}
fit8.a.3 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                housepov + (1 | schoolid/classid) + (0 + minority || schoolid), dat, subset = in_sample)
summary(fit8.a.3)
```

b. Retry part (a), allowing the slopes to be correlated with the random intercepts.

```{r}
fit8.b.1 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                housepov + (1 | schoolid/classid) + (ses || schoolid), dat, subset = in_sample)
summary(fit8.b.1)
```

```{r}
fit8.b.2 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                housepov + (1 | schoolid/classid) + (ses || schoolid), dat, subset = in_sample)
summary(fit8.b.2)
```

```{r}
fit8.b.3 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                housepov + (1 | schoolid/classid) + (ses || schoolid), dat, subset = in_sample)
summary(fit8.b.3)
```

c. Report anything unusual about the variance components (changes that are unexpected)
**Answer:**  The last 3 models with slopes correlated with random intercepts failed to converge. One unusual thing is that the model with a random slope for minority has no change in the variance components.

9. a. Take the two predictors that had significant (at .05 level) random slopes, in the forms in which they worked (indep. or correlated) and add both to the model, and test for need of one conditional on already including the other.
```{r}
fit9 <- lmer( math1st ~ ses + minority + sex + yearstea + mathknow + mathprep + 
                housepov + (1 | schoolid/classid) + (0 + sex + ses || schoolid), dat, subset = in_sample)

anova(fit8.a.1, fit9) #P = 0.4282
anova(fit8.a.2, fit9) #P = 0.0333
```
  b. Is the more complex model (with both random slopes in it) justified?
  **Answer:** It is only justified compared to the model that has just sex as a random slope. Based on the LRT having ses with a random slope as well is justified based on the 0.03 p-value.
  c. WRITE OUT THIS MODEL in your preferred notation (include assumptions)
$MATH1ST_{ijk} = {b_0} + (b_1+\zeta_{1k})SES_{ijk} + b_2MINORITY_{ijk} + (b_3+\zeta_{3k})SEX_{ijk} + b_4YEARSTEA_{jk} + b_5MATHKNOW_{jk} + b_6MATHPREP_{jk}+ b_7HOUSEPOV_{k} + \zeta _{0k} + \eta _{0jk}+ {\varepsilon _{ijk}}$, with
${\zeta_{0k}}\sim N(0,\sigma_{\zeta_0}^2)$, ${\zeta_{1k}}\sim N(0,\sigma_{\zeta_1}^2)$, ${\zeta_{3k}}\sim N(0,\sigma_{\zeta_3}^2)$
$\eta _{0jk} \sim N(0,\sigma_{\eta_0}^2)$ and 
${\varepsilon_{ijk}}\sim N(0,\sigma_\varepsilon^2)$

10. Now consider the model with a random slope <em>only</em> in minority. We will make predictions at levels of minority in the range 0 to 1 for illustrative purposes.
  a. What are: V_C, V_S(minority=0), V_E?
    i. We need to list 'minority=0' here, or we don't know how to use the slope variance.
    
  b. What are: V_S(minority=0.25), V_S(minority=+0.50), V_S(minority=+0.75)?
  c. Is the variance between schools monotonically <em>increasing</em> in the value of minority?
